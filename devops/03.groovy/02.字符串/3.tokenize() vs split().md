

## 1.split()返回string[]， tokenize()返回list 


## 2.tokenize()忽略空字符串

String testString = 'hello brother'
assert testString.split() instanceof String[]
assert ['hello','brother']==testString.split() //split with no arguments
assert['he','','o brother']==testString.split('l')

assert testString.tokenize() instanceof List
assert ['hello','brother']==testString.tokenize() //tokenize with no arguments
assert ['he','o brother']==testString.tokenize('l')

## 3.tokenize()使用字符串内的所有字符

String  testString1='hello world'
assert ['hel',' world']==testString1.split('lo')
assert ['he',' w','r','d']==testString1.tokenize('lo')

## 4.split()可以使用正则表达式


String testString2='hello world 123 herload'
assert['hello world ',' herload']==testString2.split(/\d{3}/)


## 参考

1. https://blog.csdn.net/dora_310/article/details/52895835