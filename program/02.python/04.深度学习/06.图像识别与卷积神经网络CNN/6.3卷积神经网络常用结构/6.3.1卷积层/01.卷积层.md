
## 1. 过滤器 filter

1. 过滤器filter或内核kernel
    1. `过滤器`将当前层神经网络上的一个子节点矩阵转化为下一层神经网络上的一个单位节点矩阵
    2. `单位节点矩阵`指的是一个长和宽都为1，但深度不限的节点矩阵

## 2. 过滤器结构

1. 过滤器结构
    1. 过滤器的尺寸。过滤器所处理的节点矩阵的长和宽，常用的过滤器尺寸有 3*3 或 5*5 
    2. 过滤器处理的矩阵深度和当前层神经网络节点矩阵的深度是一致的，所以虽然节点举证是三维的，但过滤器的尺寸只需要指定两个维度
    3. 处理得到的单位节点矩阵的深度需要人工指定
    4. 过滤器的尺寸指的是一个过滤器输入节点矩阵的大小，而深度指的是输出单位节点矩阵的深度

## 3. 将节点矩阵变化为单位节点矩阵


## 4. padding

1. zero-padding
    1. 为了`避免尺寸的变化`，可以在当前矩阵的边界上加入全0填充(zero-padding)

使用 padding 和不使用 padding 的输出维度

使用 padding=全零填充，SAME，入长/步长，（如果不能整除，向上取整）
不使用 padding，VALID，(入长-核长+1)/步长，（向上取整）

padding公式
首先，定义变量：
输入图片的宽和高：i_w 和 i_h
输出特征图的宽和高：o_w 和 o_h
过滤器的宽和高：f_w 和 f_h
宽和高方向的步长：s_w 和 s_h
宽和高方向总的补零个数：pad_w 和 pad_h
顶部和底部的补零个数：pad_top 和 pad_bottom
左部和右部的补零个数：pad_left 和 pad_right

2. VALID模式，输出的宽和高为
o_w = （i_w - f_w + 1）/ s_w #（结果向上取整）
o_h = （i_h - f_h + 1）/ s_h  #（结果向上取整）
3. SAME模式，输出的宽和高为
o_w = i_w / s_w#（结果向上取整）
o_h = i_h / s_h#（结果向上取整）

    各个方向的补零个数为：max()为取较大值，

pad_h = max（( o_h -1 ) × s_h + f_h - i_h ， 0）
 pad_top = pad_h / 2  # 注意此处向下取整
 pad_bottom = pad_h - pad_top
 pad_w = max（( o_w -1 ) × s_w + f_w - i_w ， 0）
 pad_left = pad_w / 2 # 注意此处向下取整
 pad_right = pad_w - pad_left

## 5. 步长

1. 步长
    1. 设置过滤器移动的步长来调整结果矩阵的大小

## 参考

1. https://www.cnblogs.com/solomonxu/articles/9746777.html
2. https://github.com/cs231n/cs231n.github.io/blob/master/convolutional-networks.md
3. http://vision.stanford.edu/teaching/cs231n/
4. [【TensorFlow】一文弄懂CNN中的padding参数](https://www.cnblogs.com/White-xzx/p/9497029.html)