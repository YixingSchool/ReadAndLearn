
## 1. TensorFlow中声明矩阵变量的方法

```py
import tensorflow as tf

# 1. 2*3的矩阵，矩阵中的元素是均值为0，标准差为1的随机数据
# 2. 通过seed参数设定了随机种子，保证每次运行得到的结果是一样的
w1= tf.Variable(tf.random_normal([2, 3], stddev=1, seed=1))
w2= tf.Variable(tf.random_normal([3, 1], stddev=1, seed=1))
x = tf.constant([[0.7, 0.9]])

with tf.Session() as sess:
    #运行变量的initializer。调用op之前，所有变量都应被显式地初始化过。
    sess.run(w1.initializer)
    sess.run(w2.initializer)
    
    #查看值
    print (w1.eval())
    print (w2.eval())

# [[-0.8113182   1.4845988   0.06532937]
#  [-2.4427042   0.0992484   0.5912243 ]]
# [[-0.8113182 ]
#  [ 1.4845988 ]
#  [ 0.06532937]]
```

## 2. 通过变量实现神经网络的参数并实现前向传播的过程

```py
import tensorflow as tf

w1= tf.Variable(tf.random_normal([2, 3], stddev=1, seed=1))
w2= tf.Variable(tf.random_normal([3, 1], stddev=1, seed=1))
x = tf.constant([[0.7, 0.9]])

a = tf.matmul(x, w1)
y = tf.matmul(a, w2)

sess = tf.Session()
sess.run(w1.initializer)    # 初始化w1
sess.run(w2.initializer)    # 初始化w2
print(sess.run(y))          # 初始化w1和w2后，才能获取y的值
sess.close()
```

## 3. tf.initialize_all_variables函数实现初始化所有变量

```py
init_op = tf.initialize_all_variables()
sess.run(init_op)
```

## 4. GraphKeys.TRAINABLE_VARIABLES集合

* TensorFlow集合collection
    1. 所有变量都会被自动加入GraphKeys.VARIABLES这个集合
    2. tf.all_variables函数可以拿到当前计算图上所有的变量
    3. 声明变量时参数trainable为True，这个变量将会被加入GraphKeys.TRAINABLE_VARIABLES集合
    4. tf.trainable_variables函数得到所有需要优化的参数
    5. TensorFlow中提供的神经网络优化算法会将`GraphKeys.TRAINABLE_VARIABLES`集合中的变量作为默认的优化对象

## 5. 维度shape和类型type

* 变量
    * 变量在构建之后，类型就不能再改变了
    * v = tf.Variable([1,2], dtype=tf.float32)