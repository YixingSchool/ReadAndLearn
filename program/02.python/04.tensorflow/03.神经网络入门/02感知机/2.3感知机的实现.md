
# 1. 与门的实现

1. 简单的实现

```py
def AND(x1, x2):
    w1, w2, theta = 0.5, 0.5, 0.7
    tmp = x1*w1 + x2*w2
    if tmp <= theta:
        return 0
    elif tmp > theta:
        return 1

AND(0, 0) # 输出0
AND(1, 0) # 输出0
AND(0, 1) # 输出0
AND(1, 1) # 输出1
```

2. 使用权重和偏置的实现

```py
def AND(x1, x2):
    x = np.array([x1, x2])
    w = np.array([0.5, 0.5])
    b = -0.7
    tmp = np.sum(w*x) + b
    if tmp <= 0:
        return 0
    else:
        return 1
```

3. 权重和偏置
    1. `权重`：$ w_1 和 w_2 $ 是控制输入信号的重要性的参数
    2. `偏置`
        1. 把−θ命名为偏置b
        2. 偏置是调整神经元被激活的容易程度的参数。

# 2. 与非门

```py
def NAND(x1, x2):
    x = np.array([x1, x2])
    w = np.array([-0.5, -0.5])  # 仅权重和偏置与AND不同！
    b = 0.7                     # 仅权重和偏置与AND不同！
    tmp = np.sum(w*x) + b
    if tmp <= 0:
        return 0
    else:
        return 1
```

# 3. 或门

```py
def OR(x1, x2):
    x = np.array([x1, x2])
    w = np.array([-0.5, -0.5])  # 仅权重和偏置与AND不同！
    b = -0.2                    # 仅权重和偏置与AND不同！
    tmp = np.sum(w*x) + b
    if tmp <= 0:
        return 0
    else:
        return 1
```

1. 在与非门和或门的实现中，仅设置权重和偏置的值这一点和与门的实现不同


# 参考

1. 深度学习入门.基于Python的理论与实现.斋藤康毅.2018 -> 2.3感知机的实现