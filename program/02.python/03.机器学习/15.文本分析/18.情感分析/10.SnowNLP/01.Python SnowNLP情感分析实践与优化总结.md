Python SnowNLP情感分析实践与优化总结 - 简书 https://www.jianshu.com/p/886880f19a09

由于语料缺乏，前期若使用到情感分析，建议暂时使用SnowNLP（此模块主要使用淘宝评论语料）做情感挖掘，但不仅仅为单纯调用，需要优化，下面是一些实践思考：

可在此基础上优化，比如文本需要特别处理，除了平常的去停用词外，还可以需要对输入的文本结合词性等进行处理。

下面是一些常识：

一）无情感的词语(如去停用词，去掉语气词，无词性标签的词语）

二）对于文本过长，则可以考虑提取关键词或抽取文本摘要后再提取关键词

对于后者实践结果差异明显：

以"发布了头条文章：《5分钟11亿！京东双11场景化产品消费增长明显》 5分钟11亿！京东双11场景化产品消费增长明显"为例子，显然该文本为“积极****”文本。

1）s = SnowNLP（"发布了头条文章：《5分钟11亿！京东双11场景化产品消费增长明显》 5分钟11亿！京东双11场景化产品消费增长明显"）

 s.sentiment
得分为0.5，明显不符合

2）s = SnowNLP（“ ”.join(jieba.analyse.textrank("发布了头条文章：《5分钟11亿！京东双11场景化产品消费增长明显》 5分钟11亿！京东双11场景化产品消费增长明显")))

 s.sentiment

 **而抽取关键词后，得分0.8 符合**
而对于文本特别长的，则可以先抽取摘要，再对摘要提取关键词。

这主要由于此SnowNLP主要用贝叶斯机器学习方法进行训练文本，机器学习在语料覆盖上不够，特征上工程处理不当会减分，也没考虑语义等。

为何要考虑语义层面：

以“苏宁易购，是谁给你们下架OV的勇气****” 中的“下架”其实才是中心词（为表达愤怒的文本），但“勇气”为下架的宾语（其为积极的文本），此句应该结果小于0.5，但实际为0.88，去掉“苏宁易购”则为0.6>