
支持向量机分类器Support Vector Classifier，是根据训练样本的分布，搜索所有可能的线性分类器中最佳的那个。

支持向量机在海量甚至高纬度的数据中，筛选对预测任务最为有效的少数训练样本。这样做不仅节省了模型学习所需要的数据内存，同时也提高了模型的预测性能。然而，要获得如此的优势就必然要付出更多的计算代价（CPU资源和计算时间）

```py
from sklearn.datasets import load_digits
digits=load_digits()
# 该手写体数字的数码图像数据共有1797条，并且每幅图片是由8*8=64的像素矩阵表示
digits.data.shape
# (1797L, 64L)

# from sklearn.cross_validation import train_test_split
from sklearn.model_selection import train_test_split
#随机选取75%的数据作为训练样本；其余25%的数据作为测试样本
x_train, x_test, y_train, y_test=train_test_split(digits.data, digits.target, test_size=0.25, random_state=33)
y_train.shape #(1347L,)
y_test.shape #(450L,)

#对训练和测试的特征数据进行标准化
#标准化数据，保证每个维度的特征数据方差为1，均值为0。使得预测结果不会被某些维度过大的特征值而主导
from sklearn.preprocessing import StandardScaler
from sklearn.svm import LinearSVC
ss = StandardScaler()
x_train = ss.fit_transform(x_train)
x_test = ss.transform(x_test)

lsvc=LinearSVC()
lsvc.fit(x_train, y_train)
y_predict=lsvc.predict(x_test)

#性能测评：使用准确性、找回率、精确率和F1指标
print('The Accuracy of Linear SVC is',lsvc.score(x_test,y_test))
#Output:The Accuracy of Linear SVC is 0.953333333333
from sklearn.metrics import classification_report
print(classification_report(y_test,y_predict,target_names=digits.target_names.astype(str)))
#               precision    recall  f1-score   support
#
#            0       0.92      1.00      0.96        35
#            1       0.96      0.98      0.97        54
#            2       0.98      1.00      0.99        44
#            3       0.93      0.93      0.93        46
#            4       0.97      1.00      0.99        35
#            5       0.94      0.94      0.94        48
#            6       0.96      0.98      0.97        51
#            7       0.92      1.00      0.96        35
#            8       0.98      0.84      0.91        58
#            9       0.95      0.91      0.93        44
#
#     accuracy                           0.95       450
#    macro avg       0.95      0.96      0.95       450
# weighted avg       0.95      0.95      0.95       450
```

# 2. 精准度和召回度

精确度是`搜索结果有多大用处`，而召回是`结果如何完整`
1. 准确率（Precision）：P=TP/(TP+FP)。通俗地讲，就是预测正确的正例数据占预测为正例数据的比例。
2. 召回率（Recall）：TPR(true positive rate) = TP/(TP+FN) = TP/P。通俗地讲，就是预测为正例的数据占实际为正例数据的比例
3. FPR(false positive rate) = FP / (FP + TN) 表示当前被错误分到正样本类别中真实的负样本所占所有负样本总数的比例；

概念：
1. 真正TP, true positives, 实际是正例，预测为正例
2. 伪反FN, false negatives, 实际为正例，预测为负例
3. 伪正FP, false positives, 实际为负例，预测为正例
4. 真反TN, true negatives, 实际为负例，预测为负例

ROC:
1. 对于ROC来说，横坐标就是FPR，而纵坐标就是TPR
2. 因此可以想见，当 TPR越大，而FPR越小时，说明分类结果是较好的

# 3. sklearn中的classification_report函数

https://blog.csdn.net/akadiao/article/details/78788864

sklearn中的classification_report函数用于显示主要分类指标的文本报告．在报告中显示每个类的精确度，召回率，F1值等信息。 主要参数: 
1. y_true：1维数组，或标签指示器数组/稀疏矩阵，目标值。 
2. y_pred：1维数组，或标签指示器数组/稀疏矩阵，分类器返回的估计值。 
3. labels：array，shape = [n_labels]，报表中包含的标签索引的可选列表。 
4. target_names：字符串列表，与标签匹配的可选显示名称（相同顺序）。 
5. sample_weight：类似于shape = [n_samples]的数组，可选项，样本权重。 
6. digits：int，输出浮点值的位数．


classification_report用法示例：
```py
from sklearn.metrics import classification_report
y_true = [0, 1, 2, 2, 2]
y_pred = [0, 0, 2, 2, 1]
target_names = ['class 0', 'class 1', 'class 2']
print(classification_report(y_true, y_pred, target_names=target_names))
# 输出：
#              precision    recall  f1-score   support
#     class 0       0.50      1.00      0.67         1
#     class 1       0.00      0.00      0.00         1
#     class 2       1.00      0.67      0.80         3
# avg / total       0.70      0.60      0.61         5
```
结果：
1. 其中列表左边的一列为分类的标签名，
2. 右边support列为每个标签的出现次数
3. avg / total行为各列的均值（support列为总和）． 
4. precision recall f1-score三列分别为各个类别的精确度/召回率及 F1 F1值．


# 参考

1. 06#PYTHON机器学习及实践.从零开始通往KAGGLE竞赛之路.2016 -> 2.1.1.2.支持向量机分类
2. 01#机器学习实战.Peter.2013 -> 06.支持向量机SVM
3. 支持向量机通俗导论（理解SVM的三层境界） - 结构之法 算法之道 - CSDN博客 https://blog.csdn.net/v_JULY_v/article/details/7624837

2. 数据特征的标准化和归一化你了解多少？ http://www.raincent.com/content-10-12066-1.html
3. 什么是数据【标准化】【归一化】，他们有什么作用？ https://blog.csdn.net/qq_25439417/article/details/82532097
4. 机器学习——标准化/归一化的目的和作用 https://blog.csdn.net/zenghaitao0128/article/details/78361038
5. 数据预处理之数据无量纲化(标准化/归一化) - 小方哥哥的博客 - CSDN博客 https://blog.csdn.net/OnTheWayGoGoing/article/details/79871559
6. ModuleNotFoundError: No module named 'sklearn.cross_validation' - 不服输的南瓜的博客 - CSDN博客 https://blog.csdn.net/weixin_40283816/article/details/83242083
7. 机器学习笔记－－classification_report&精确度/召回率/F1值 - akadiao的博客 - CSDN博客 https://blog.csdn.net/akadiao/article/details/78788864
8. 准确率，召回率，F1 值、ROC，AUC、mse,mape评价指标 - 雪伦的专栏 - CSDN博客 https://blog.csdn.net/a819825294/article/details/51699211
9. ROC、Precision、Recall、TPR、FPR理解 - 简书 https://www.jianshu.com/p/be2e037900a1
10. 机器学习基础（1）- ROC曲线理解 - 简书 https://www.jianshu.com/p/2ca96fce7e81
11. 机器学习笔记－－classification_report&精确度/召回率/F1值 - akadiao的博客 - CSDN博客 https://blog.csdn.net/akadiao/article/details/78788864