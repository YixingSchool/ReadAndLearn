
# 第 14 章 流量控制

* 流量控制
  * 访问速度
  * 资源占用
  * 并发连接数
  * 并发访问数

## 14.1 静态流控

* 静态流控
  * 主要针对`客户端访问速率`进行控制
* 传统静态流控设计方案
  * 根据集群服务节点个数和静态流控阈值，计算每个服务节点分摊的QPS阈值
  * 在多线程情况下，使用Atomic原子类进行计数
  * 达到阈值拒绝新的请求消息接入
  * 不拒绝后续的应答消息，避免触发Failover
* 传统方案缺点
  * 忽略了实例的动态变化
* 动态配额分配制
  * 服务启动或节点变更时，动态推送每个节点分配的流控阈值QPS
  * 根据各个节点的性能KPI数据做加权
  * 配额有剩余返还给服务注册中心，配额已用完的重新申请配额
* 动态配额申请制
  * 拿出一定比例的配额做初始分配，剩余放在配额资源池中
  * 用完配额，主动向服务注册中心申请配额
  * 总配额申请完，对新接入的请求消息进行流控
  * 优点
    * 性能KPI在本地内存中计算
    * 性能高有高配额

## 14.2 动态流控

* 动态流控
  * 主要是资源
    * 系统资源
    * 应用资源
* 动态流控因子
  * 系统资源：判断操作系统类型后，调用相关的操作系统资源采集接口实现类
  * 应用资源
    * JVM堆内存使用率
    * 消息队列积压率
    * 会话积压率
* 分级流控
  * 动态流控分级别，不同级别拒绝的消息比例不同
  * 连续采集N次并计算平均值不会发生流控级别的`跳变`

## 14.3 并发控制

* 并发控制
  * 针对`线程的并发执行数`进行控制
* 形式
  * 针对服务提供者的全局控制
  * 针对服务消费者的局部控制
* 服务端全局控制
  * 接口并发执行数
  * 接口方法并发执行数
* 服务消费者流控

## 14.4 连接控制

防止因为消费者连接数过多导致服务端负载压力过大

## 14.5 并发和连接控制算法

* 并发和链接控制算法
  * 基于服务调用Pipeline机制，对请求消息接收和发送、应答消息接收和发送、异常消息等做切面拦截
  * 用Pipeline拦截切面接口，对请求消息做服务调用前的拦截和计数
* 服务端算法
  * 从全局RPC上下文获取当前的并发执行数
  * 等于或大于流控阈值，抛出RPC流控异常给客户端
  * 服务调用执行完成之后，获取RPC上下文中的并发执行数，做原子自减
* 客户端算法
  * 从全局RPC上下文获取当前的并发执行数
  * 小于流控阈值，对当前的计数器做原子自增
  * 等于或大于流控阈值，当前线程进入wait状态
  * 其他线程服务调用完成，notify当前线程


