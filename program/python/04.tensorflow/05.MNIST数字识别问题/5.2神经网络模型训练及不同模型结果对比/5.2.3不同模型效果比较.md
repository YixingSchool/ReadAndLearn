
## 1. 5种优化方法

1. 5种优化方法
    1. `激活函数`实现神经网络模型的去线性化
    2. 使用一个或多个`隐含层`使得神经网络的结构更深，以解决复杂问题
    3. `带指数衰减`的学习率设置
    4. 使用`正则化`来避免过度拟合
    5. `滑动平均模型`来使得最终模型更加健壮
2. 神经网络的结构对最终模型的效果有本质性的影响
    1. 使用了隐藏层和激活函数时可以达到大约98.4%的正确率
    2. 没有隐藏层和激活函数，模型的正确率只有大约92.6%
3. 使用滑动平均模型、指数衰减的学习率和使用正则化带来的正确率的提升并不是特别明显
    1. 滑动平均模型和指数衰减的学习率在一定程度上都是限制神经网络中参数更新的速度
    2. 前4000轮迭代对模型的改变是最大的
    3. 在4000轮之后，因为梯度本身比较小，所以参数的改变也就比较缓慢。于是滑动平均模型或者指数衰减的学习率的作用也就没有那么突出了
    4. 当问题更加复杂时，迭代不会这么快接近收敛，这时滑动平均模型和指数衰减的学习率可以发挥更大的作用

## 2. 使用加入正则化的损失函数给模型效果代理的提升要相对显著

1. 两个使用不同损失函数的神经网络模型
    1. 只最小化交叉熵损失
        1. 在训练数据上的交叉熵损失要比优化总损失的模型更小
        2. 在测试数据上，优化总损失的模型却要好于只优化交叉熵的模型
    2. 交叉熵和L2正则化损失的和
2. 只优化交叉熵的模型可以更好的拟合训练数据(交叉熵损失更小)，但是却不能很好的挖掘数据中潜在的规律来判断未知的测试数据