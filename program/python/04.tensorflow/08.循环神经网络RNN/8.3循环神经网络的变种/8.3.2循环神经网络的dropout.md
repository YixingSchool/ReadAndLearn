
## 1. dropout

1. dropout
    1. 卷积神经网络只在最后的全连接层中使用dropout
    2. 循环神经网络只在不同层循环体结构之间使用dropout，而不在同一层的循环体结构之间使用
    3. 从t-1传递到t时，循环神经网络不会进行dropout；而是在同一时刻t中，不同层循环体之间会使用dropout

## 2. DropoutWrapper实现dropout

```py
#定义一个LSTM结构。LSTM中使用的变量也会在该函数中自动声明
lstm = rnn_cell.BasicLSTMCell(lstm_size)
#两个参数控制dropout的概率：input_keep_prob控制输入的dropout，output_keep_prob控制输出的概率
dropout_lstm = tf.nn.rnn_cell.DropoutWrapper(lstm, output_keep_prob=0.5)
#通过MultiRNNCell类实现深层循环神经网络中每一个时刻的前向传播过程。number_of_layers表示有多少层
stacked_lstm = rnn_cell.MultiRNNCell([dropout_lstm] * number_of_layers)
#将LSTM中的状态初始化为全为0数组，batch_size给出一个batch的大小
state = lstm.zero_state(batch_size, tf.float32)
```