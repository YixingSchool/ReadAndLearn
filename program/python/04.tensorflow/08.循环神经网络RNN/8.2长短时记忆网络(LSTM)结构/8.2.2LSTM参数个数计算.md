
LSTM参数个数计算 - taoyafan的博客 - CSDN博客 https://blog.csdn.net/taoyafan/article/details/82803943

1. LSTM
    1. （1）第一层是一个 embedding 层，输出是 100 维的。
    2. （2）第二层是一个 LSTM 层，输出是 512 维的。
    3. LSTM这一层的参数个数是 1255424 个，
2. 设 LSTM 输入维度为 x_dim， 输出维度为 y_dim，那么参数个数 n 为：
    1. n = 4 * ((x_dim + y_dim) * y_dim + y_dim)
    2. 对应的网络结构就是：n = 4 * ((100 + 512) * 512 + 512) = 1255424

## 2. LSTM 的原理以及公式

h = np.tanh(np.dot(Wxh, x) + np.dot(Whh, h) + bh)

```py
import numpy as np

vocab_size = 65
# hyperparameters
hidden_size = 100  # size of hidden layer of neurons
seq_length = 25  # number of steps to unroll the RNN for
learning_rate = 1e-1

Wxh = np.random.randn(hidden_size, vocab_size) * 0.01  # input to hidden
Whh = np.random.randn(hidden_size, hidden_size) * 0.01  # hidden to hidden
Why = np.random.randn(vocab_size, hidden_size) * 0.01  # hidden to output
bh = np.zeros((hidden_size, 1))  # hidden bias
by = np.zeros((vocab_size, 1))  # output bias

h = np.zeros((hidden_size, 1))  # h is Hx1 array of initial hidden state
x = np.zeros((vocab_size, 1))

Wxh.shape               # (100, 65)
x.shape                 # (65, 1)
Whh.shape               # (100, 100)
h.shape                 # (100, 1)

np.dot(Wxh, x).shape    # (100, 1)
np.dot(Whh, h).shape    # (100, 1)
bh.shape                # (100, 1)

h = np.tanh(np.dot(Wxh, x) + np.dot(Whh, h) + bh)
```

## 参考

1. machine learning from scratch
    1. https://github.com/rockyzhengwu/mlscratch.git
    2. https://github.com/eriklindernoren/ML-From-Scratch
    3. https://github.com/subarnop/AMachineLearningWalkThrough
    4. https://download.csdn.net/download/zwxeye/10459112
2. https://www.cnblogs.com/jermmyhsu/p/10020308.html
3. https://www.cnblogs.com/wushaogui/p/9176617.html
